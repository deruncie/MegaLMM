% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/helper_functions.R
\name{estimate_memory_posterior}
\alias{estimate_memory_posterior}
\title{Estimates the memory required to store a set of posterior samples collected by \code{sample_MegaLMM}}
\usage{
estimate_memory_posterior(MegaLMM_state, n_iter)
}
\arguments{
\item{MegaLMM_state}{The model after calling \code{clear_Posterior}}

\item{n_iter}{number of iterations of the Gibbs sampler}
}
\value{
The estimated memory size in bytes
}
\description{
A call to \code{sample_MegaLMM(MegaLMM_state,n_iter)} will run \code{n_iter}
of the Gibbs sampler. If \code{nrun > burn}, then a posterior sample of all variables
stored in \code{MegaLMM_state$Posterior} every \code{thin} iteration. If you are doing
a long run, and storing a large number of parameters, this will take a lot of memory.
This function will estimate the memory requirements.
}
\details{
Note 1: The estimated value will assume all iterations are post-burnin

Note 2: \code{sample_MegaLMM()} will instantiate all arrays to hold the posterior samples
prior to running the iterations, so memory requirements will not increase much during the sampling.

Note 3: It is generally not needed to run \code{sample_MegaLMM(MegaLMM_state,n_iter)} 
with a large \code{n_iter}. Instead, run the function many times, each with a small \code{n_iter},
calling \code{\link{save_posterior_chunk}} between each run. This gives you the ability
to diagnose problems during the run, and keeps the memory requirments low. You can always
reload the posterior samples from the database on the disk using \code{\link{reload_Posterior}} or
\code{\link{load_posterior_param}}.
}
\examples{
estimate_memory_posterior(MegaLMM_state,100)
}
\seealso{
\code{\link{estimate_memory_initialization_MegaLMM}}, 
\code{\link{save_posterior_chunk}}, \code{\link{reload_Posterior}},
\code{\link{load_posterior_param}}
}
